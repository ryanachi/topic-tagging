{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vect = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idToTagIndex = {}          #dict mapping post ID to a list of tag indices\n",
    "tagToTagIndex = {}         #dict mapping tag to tag index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def truncate(number, digits) -> float:\n",
    "    stepper = 10.0 ** digits\n",
    "    return math.trunc(stepper * number) / stepper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'OwnerUserId', 'CreationDate', 'ClosedDate', 'Score', 'Title',\n",
      "       'Body'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "with open(\"stacksample/Questions-ascii-1M.csv\") as question_input:\n",
    "    questions_data = pd.read_csv(question_input, engine='python')\n",
    "\n",
    "    print(questions_data.columns)\n",
    "    questions_data = questions_data[['Id', 'Body']]\n",
    "    questions_data.insert(len(questions_data.columns), 'Code', \"\")\n",
    "    \n",
    "    a = re.compile(r'<pre><code>([^<]*)</code></pre>')\n",
    "    b = re.compile(r'<.*?>')\n",
    "    questions_data['Code'] = questions_data['Body'].apply(lambda x: ' '.join(re.findall(a, x)))\n",
    "\n",
    "    def clean(text):\n",
    "        x = re.sub(a, '', text)\n",
    "        x = re.sub(b, '', x)\n",
    "        x = x.replace('\\n\\n', '\\n')\n",
    "        return x\n",
    "    questions_data['Body'] = questions_data['Body'].apply(clean)\n",
    "    \n",
    "#     questions_data['Body'] = questions_data['Body'].apply(nltk.tokenize.word_tokenize) #need to fix: don't convert\n",
    "#     # C#, C++ to C\n",
    "#     questions_data['Body'] = questions_data['Body'].apply(lambda x: [word for word in x if word.isalnum()])\n",
    "#     questions_data['Body'] = questions_data['Body'].apply(lambda x: [word.lower() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152759it [00:13, 11181.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "idToTagIndex = {}          #dict mapping post ID to a list of tag indices\n",
    "tagToTagIndex = {}         #dict mapping tag to tag index\n",
    "tagIndexToTag = {}\n",
    "tagToFrequency = defaultdict(lambda: 0)\n",
    "\n",
    "with open(\"stacksample/tags-1M.csv\") as tag_input:\n",
    "    tag_data = pd.read_csv(tag_input)\n",
    "    tagIndex = 0\n",
    "    for index, row in tqdm(tag_data.iterrows()):\n",
    "        currId = int(row[0])\n",
    "        currTag = row[1]\n",
    "        if currTag not in tagToTagIndex:\n",
    "            tagToTagIndex[currTag] = tagIndex\n",
    "            tagIndexToTag[tagIndex] = currTag\n",
    "            currTagIndex = tagIndex\n",
    "            tagIndex += 1\n",
    "\n",
    "        else:\n",
    "            currTagIndex = tagToTagIndex[currTag]  \n",
    "        \n",
    "        tagToFrequency[currTagIndex] += 1        \n",
    "    \n",
    "        if currId not in idToTagIndex.keys():\n",
    "            idToTagIndex[currId] = [tagToTagIndex[row[1]]]\n",
    "        else:\n",
    "            idToTagIndex[currId].append(tagToTagIndex[row[1]])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  53203\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples: \", len(idToTagIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c# (14): 6722 times\n",
      "java (89): 3858 times\n",
      ".net (15): 3598 times\n",
      "php (76): 3223 times\n",
      "asp.net (8): 3041 times\n",
      "javascript (132): 2852 times\n",
      "c++ (18): 2509 times\n",
      "jquery (370): 2198 times\n",
      "iphone (607): 2111 times\n",
      "python (196): 2070 times\n"
     ]
    }
   ],
   "source": [
    "# find 10 most common tags\n",
    "\n",
    "tagToFrequencyList = []\n",
    "\n",
    "for key, value in tagToFrequency.items():\n",
    "    temp = [key, value]\n",
    "    tagToFrequencyList.append(temp)\n",
    "    \n",
    "tagToFrequencyList.sort(reverse=True, key=lambda x: x[1])\n",
    "\n",
    "for tag in tagToFrequencyList[:10]:\n",
    "    print(f\"{tagIndexToTag[tag[0]]} ({tag[0]}): {tag[1]} times\")\n",
    "    \n",
    "mostCommonTags = {}\n",
    "for counter, tag in enumerate(tagToFrequencyList[:10]):   #currently takes top 10 tags\n",
    "    mostCommonTags[tag[0]] = counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{14: 0, 89: 1, 15: 2, 76: 3, 8: 4, 132: 5, 18: 6, 370: 7, 607: 8, 196: 9}\n"
     ]
    }
   ],
   "source": [
    "# list(idToTagIndex.values())[:10]\n",
    "print(mostCommonTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Id                                               Body  \\\n",
      "0           80  I've written a database generation script in S...   \n",
      "1           90  Are there any really good tutorials explaining...   \n",
      "2          120  Has anyone got experience creating SQL-based A...   \n",
      "3          180  This is something I've pseudo-solved many time...   \n",
      "4          260  I have a little game written in C#. It uses a ...   \n",
      "...        ...                                                ...   \n",
      "53198  2495810  I'm going to host an app on a shared host and ...   \n",
      "53199  2495870  I use MouseMove event to move objects(say labe...   \n",
      "53200  2495890  I have dragged a empty asp.net table onto my w...   \n",
      "53201  2495910  I want to log some seemingly random errors I'm...   \n",
      "53202  2496040  I have a php array that has a bunch of data th...   \n",
      "\n",
      "                                                    Code Top-Tags  \n",
      "0      Create Table tRole (\\n      roleID integer Pri...       []  \n",
      "1                                                              []  \n",
      "2                                                             [4]  \n",
      "3                                                              []  \n",
      "4      ICard Cards[current] = new MyGame.CardLibrary....   [0, 2]  \n",
      "...                                                  ...      ...  \n",
      "53198                                                          []  \n",
      "53199  OnMouseMove(e MouseEventArgs)\\n    if e.Button...      [2]  \n",
      "53200  if (IsPostBack == false)\\n{\\n    // check if d...   [0, 4]  \n",
      "53201                                                          []  \n",
      "53202  var points = [\\n['test name', 37.331689, -122....   [3, 5]  \n",
      "\n",
      "[53203 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "idToTenTags = {}\n",
    "\n",
    "for postId, tags in idToTagIndex.items():\n",
    "    containsTopTenTags = [mostCommonTags[tag] for tag in tags if tag in mostCommonTags.keys()]\n",
    "    idToTenTags[postId] = containsTopTenTags\n",
    "    \n",
    "questions_data['Top-Tags'] = questions_data['Id'].apply(lambda x: idToTenTags[x])\n",
    "\n",
    "print(questions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'to', 'i', 'a', 'is', 'and', 'in', 'of']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(questions_data['Body'].values.tolist())\n",
    "vectorizer.adapt(text_ds)\n",
    "vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "questions_X = vectorizer(np.array([[s] for s in questions_data['Body'].values])).numpy()\n",
    "questions_y = mlb.fit_transform(np.array(questions_data['Top-Tags'].values))\n",
    "print(questions_y[:5])\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(questions_X, questions_y, train_size=0.75, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4,  124,  176,   12,  166,    9,   40,   15,   26, 1701,    5,\n",
       "         393,  848,  291,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"I tried running this line of code, but I'm receiving a null pointer exception\"]])\n",
    "output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1517\n"
     ]
    }
   ],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))\n",
    "print(word_index[\"hello\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 166, 9, 40]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"this\", \"line\", \"of\", \"code\"]\n",
    "[word_index[w] for w in test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20002\n",
      "Converted 18657 words (1343 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "print(num_tokens)\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = word_vect.get_vector(word)\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    except:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 200)         4000400   \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, None, 128)         128128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_16 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "softmax_16 (Softmax)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,310,426\n",
      "Trainable params: 310,026\n",
      "Non-trainable params: 4,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(len(mostCommonTags))(x) #change to all tags\n",
    "preds = layers.Softmax(axis=-1)(preds)\n",
    "# model = keras.Model(int_sequences_input, preds)\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.LSTM(2, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(len(mostCommonTags), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - ETA: 0s - loss: 5.5621e-05 - top_k_categorical_accuracy: 0.75815.562078149523586e-05\n",
      "0.7581073641777039\n",
      "0.20028650760650635\n",
      "0.9373731017112732\n",
      "312/312 [==============================] - 48s 155ms/step - loss: 5.5621e-05 - top_k_categorical_accuracy: 0.7581 - val_loss: 0.2003 - val_top_k_categorical_accuracy: 0.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1750c0c50>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import tensorflow.keras.callbacks as cbks\n",
    "class CustomMetrics(cbks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k in logs:\n",
    "            print(logs[k])\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    print(\"y_true\")\n",
    "    print(K.print_tensor(y_true))\n",
    "    print(\"y_pred\")\n",
    "    print(K.print_tensor(y_pred))\n",
    "    \n",
    "  \n",
    "    \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              #loss = custom_loss,\n",
    "              metrics = [tf.keras.metrics.TopKCategoricalAccuracy(k=5)]) \n",
    "              #metrics = 'accuracy'\n",
    "              #metrics = custom_metric)                \n",
    "\n",
    "weights = {}\n",
    "\n",
    "for i in range(10):\n",
    "    weights[i] = (1 / tagToFrequencyList[i][1])\n",
    "\n",
    "model.fit(train_X, train_y, batch_size=128, epochs=1, validation_data=(test_X, test_y), class_weight=weights, callbacks = [CustomMetrics()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x175323bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "c#                0.11            \n",
      "java              0.101           \n",
      ".net              0.094           \n",
      "php               0.115           \n",
      "asp.net           0.104           \n",
      "javascript        0.099           \n",
      "c++               0.085           \n",
      "jquery            0.083           \n",
      "iphone            0.1             \n",
      "python            0.104           \n",
      "\n",
      "Most likely tag: php\n"
     ]
    }
   ],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "probabilities = end_to_end_model.predict(\n",
    "#    [\"I wanted to open my app without safari system alert but I found out that is impossible. so i decided to handle this alert event but I couldn't find the way. if I click [open], then safari open App, but if I click [cancel], then 'appCheckTimer' will be executed, then safari moves to 'some page's url'. if there is no way to not open this alert, I want to handle this alert's button event, when user click [cancel], I just want to stay that page. that alert is not opened by me, it's by safari So I can't handle it.\"]\n",
    "#     [\"Dropped my iphone again :(\"]\n",
    "    [\"my name is Varuni\"]\n",
    ")\n",
    "\n",
    "for i, prob in np.ndenumerate(probabilities):\n",
    "    print('{:<16}  {:<16}'.format(tagIndexToTag[tagToFrequencyList[i[1]][0]], truncate(prob, 3)))\n",
    "print(f\"\\nMost likely tag: {tagIndexToTag[tagToFrequencyList[np.argmax(probabilities)][0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

